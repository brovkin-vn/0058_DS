{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.9 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "m6.5_Практика.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Стекинг"
      ],
      "metadata": {
        "id": "SVGEqntXHZeD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "source": [
        "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
        "                              RandomForestClassifier, ExtraTreesClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import clone\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats.distributions import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "IREftSDTHZeE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "source": [
        "dataset = load_digits()\n",
        "X, y = dataset['data'], dataset['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1J0r6DYGHZeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "97GG-s4cHZeS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
        "    \n",
        "    n_classes = len(np.unique(y_train))\n",
        "    X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\n",
        "\n",
        "    splits = cv.split(X_train)\n",
        "    for train_fold_index, predict_fold_index in splits:\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
        "        y_fold_train = y_train[train_fold_index]\n",
        "        \n",
        "        folded_clf = clone(clf)\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\n",
        "        \n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
        "    \n",
        "    meta_clf = clone(clf)\n",
        "    meta_clf.fit(X_train, y_train)\n",
        "    \n",
        "    X_meta_test = meta_clf.predict_proba(X_test)\n",
        "    \n",
        "    return X_meta_train, X_meta_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "hcomzpKcHZeU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "source": [
        "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n",
        "   \n",
        "    features = [\n",
        "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
        "        for clf in tqdm(classifiers)\n",
        "    ]\n",
        "    \n",
        "    stacked_features_train = np.hstack([\n",
        "        features_train for features_train, features_test in features\n",
        "    ])\n",
        "\n",
        "    stacked_features_test = np.hstack([\n",
        "        features_test for features_train, features_test in features\n",
        "    ])\n",
        "    \n",
        "    return stacked_features_train, stacked_features_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "IcKj44HrHZeW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "source": [
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "def compute_metric(clf, X_train=X_train, y_train=y_train, X_test=X_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "source": [
        "np.random.seed(42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4V6xy7_0HZeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "source": [
        "clf = GradientBoostingClassifier(n_estimators=300)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "accuracy_score(clf.predict(X_test), y_test)\n",
        "compute_metric(clf)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.972289"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "metadata": {
        "id": "Gbv7YXs8HZea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35cd300d-f3f9-4055-9967-3dc70b434e51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "source": [
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    LogisticRegression(C=0.001, penalty='l1', solver='saga', multi_class='ovr', max_iter=2000, random_state=42),\n",
        "    LogisticRegression(C=0.001, penalty='l1', solver='saga', multi_class='multinomial', max_iter=2000, random_state=42),\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42),\n",
        "    GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
        "], X_train, X_test, y_train, cv)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [03:52<00:00, 58.06s/it]\n"
          ]
        }
      ],
      "metadata": {
        "id": "NmrhIV1aHZec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9817055-7d57-46bd-f66e-8f0bff9c42b5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "source": [
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42),\n",
        "    ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n",
        "], X_train, X_test, y_train, cv)\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs', multi_class='auto', random_state=42)\n",
        "compute_metric(clf, X_train = stacked_features_train, y_train = y_train, X_test=stacked_features_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:33<00:00, 16.67s/it]\n",
            "/home/eos/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.976144"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "source": [
        "clf = LogisticRegression(penalty='none', solver='lbfgs', multi_class='auto', random_state=42)\n",
        "compute_metric(clf, X_train = stacked_features_train, y_train = y_train, X_test=stacked_features_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/eos/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.976144"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "source": [
        "cv = KFold(n_splits=20, shuffle=True, random_state=42)\n",
        "\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42),\n",
        "    ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n",
        "], X_train, X_test, y_train, cv)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "clf = LogisticRegression(penalty='none', solver='lbfgs', multi_class='auto', random_state=42)\n",
        "compute_metric(clf, X_train = stacked_features_train, y_train = y_train, X_test=stacked_features_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.790371"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "source": [
        "X_train = np.hstack([X_train, stacked_features_train])\n",
        "X_test = np.hstack([X_test, stacked_features_test])\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs', multi_class='auto', random_state=42)\n",
        "compute_metric(clf, X_train = X_train, y_train = y_train, X_test=X_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.986778"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "metadata": {
        "id": "KAqWN10ZHZee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "source": [
        "np.random.seed(42)\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs',multi_class='auto',random_state=42)\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test)\n",
        "# clf.fit(stacked_features_train, cover_y_train)\n",
        "# accuracy_score(clf.predict(stacked_features_test), cover_y_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/eos/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.976144"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "metadata": {
        "id": "B-wCuCCdHZef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a3137a3-815b-47ea-9fa1-639d4b2bebc2"
      }
    }
  ]
}