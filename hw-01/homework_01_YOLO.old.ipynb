{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u64t6tS-K97g"
      },
      "source": [
        "# Обучение модели YOLOv5\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDIuUhVqzGKw"
      },
      "source": [
        "## ЗАДАНИЕ\n",
        "\n",
        "Обучите модель **yolov5**,  используя готовый `train.py` файл репозитория https://github.com/ultralytics/yolov5.git.\n",
        "\n",
        "Для данной модели изображения и классы объектов должны находиться в папках images и labels, соответсвенно.\n",
        "\n",
        "Протестируйте модель на валидациооной выборке и выведите на экран полученные изображения с bbox и классами объектов.\n",
        "\n",
        "Сделайте сравнение текущей модели с Faster RCNN по скорости и качетсву."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Импорт репозитория"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n"
          ]
        }
      ],
      "source": [
        "!chcp 65001\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Установка необходимых пакетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Импрот необходимых модулей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os \n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import urllib.request\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка датасета\n",
        "data_dir = \"data/\"\n",
        "if not os.path.exists(f\"{data_dir}VOCdevkit\"):\n",
        "    if not os.path.exists(f\"{data_dir}VOC.tar\"):\n",
        "        urllib.request.urlretrieve(\n",
        "            \"https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\", f\"{data_dir}VOC.tar\"\n",
        "        )\n",
        "    with tarfile.open(f\"{data_dir}VOC.tar\") as tar:\n",
        "        tar.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuBNUWfiMGSF"
      },
      "source": [
        "### Конвертация аннотаций к формату YOLO v5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcqbGZWr082T"
      },
      "source": [
        "### Формат PASCAL VOC \n",
        "хранит свои аннотации в XML-файлах. Давайте посмотрим на один такой файл."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aHBh9hB9m_a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active code page: 65001\n",
            "<annotation>\n",
            "\t<folder>VOC2012</folder>\n",
            "\t<filename>2007_000027.jpg</filename>\n",
            "\t<source>\n",
            "\t\t<database>The VOC2007 Database</database>\n",
            "\t\t<annotation>PASCAL VOC2007</annotation>\n",
            "\t\t<image>flickr</image>\n",
            "\t</source>\n",
            "\t<size>\n",
            "\t\t<width>486</width>\n",
            "\t\t<height>500</height>\n",
            "\t\t<depth>3</depth>\n",
            "\t</size>\n",
            "\t<segmented>0</segmented>\n",
            "\t<object>\n",
            "\t\t<name>person</name>\n",
            "\t\t<pose>Unspecified</pose>\n",
            "\t\t<truncated>0</truncated>\n",
            "\t\t<difficult>0</difficult>\n",
            "\t\t<bndbox>\n",
            "\t\t\t<xmin>174</xmin>\n",
            "\t\t\t<ymin>101</ymin>\n",
            "\t\t\t<xmax>349</xmax>\n",
            "\t\t\t<ymax>351</ymax>\n",
            "\t\t</bndbox>\n",
            "\t\t<part>\n",
            "\t\t\t<name>head</name>\n",
            "\t\t\t<bndbox>\n",
            "\t\t\t\t<xmin>169</xmin>\n",
            "\t\t\t\t<ymin>104</ymin>\n",
            "\t\t\t\t<xmax>209</xmax>\n",
            "\t\t\t\t<ymax>146</ymax>\n",
            "\t\t\t</bndbox>\n",
            "\t\t</part>\n",
            "\t\t<part>\n",
            "\t\t\t<name>hand</name>\n",
            "\t\t\t<bndbox>\n",
            "\t\t\t\t<xmin>278</xmin>\n",
            "\t\t\t\t<ymin>210</ymin>\n",
            "\t\t\t\t<xmax>297</xmax>\n",
            "\t\t\t\t<ymax>233</ymax>\n",
            "\t\t\t</bndbox>\n",
            "\t\t</part>\n",
            "\t\t<part>\n",
            "\t\t\t<name>foot</name>\n",
            "\t\t\t<bndbox>\n",
            "\t\t\t\t<xmin>273</xmin>\n",
            "\t\t\t\t<ymin>333</ymin>\n",
            "\t\t\t\t<xmax>297</xmax>\n",
            "\t\t\t\t<ymax>354</ymax>\n",
            "\t\t\t</bndbox>\n",
            "\t\t</part>\n",
            "\t\t<part>\n",
            "\t\t\t<name>foot</name>\n",
            "\t\t\t<bndbox>\n",
            "\t\t\t\t<xmin>319</xmin>\n",
            "\t\t\t\t<ymin>307</ymin>\n",
            "\t\t\t\t<xmax>340</xmax>\n",
            "\t\t\t\t<ymax>326</ymax>\n",
            "\t\t\t</bndbox>\n",
            "\t\t</part>\n",
            "\t</object>\n",
            "</annotation>\n"
          ]
        }
      ],
      "source": [
        "!chcp 65001\n",
        "!type data\\VOCdevkit\\VOC2012\\Annotations\\2007_000027.xml "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Данная аннотация относится к файлу 2007_000027.jpg размером 486х500х3. Файл содерит один тэг object, описывающий класс объекта и координаты ограничивающих рамок. Класс определяется тегом name. Рамка тегами - xmin, ymin, xmax, ymax. Соответственно верхний левый угол рамки (xmin, ymin) и нижний правый (xmax, ymax). Четыре тега part описывают рамки частей объекта."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Формат YOLO v5 \n",
        "подразумевает аннотацию для каждого изображения в виде файла .txt (имя файл совпадает с именем изображения), где каждая строка текстового файла описывает ограничивающую рамку. Рассмотрим следующее изображение.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1yUJt5XTvYo4MbWxKAxhPdCk-yCnQ1AEz)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Файл аннотаций zidane.txt для приведенного выше изображения выглядит следующим образом:\n",
        "\n",
        "```\n",
        "27 0.786719 0.502778 0.0328125 0.161111 0.287125\n",
        "0 0.471875 0.629167 0.765625 0.713889 0.593856\n",
        "0 0.741406 0.522222 0.310937 0.925 0.877349\n",
        "```\n",
        "Описано три объекта. Спецификация для каждой строки выглядит следующим образом:\n",
        "\n",
        "* Одна строка на объект\n",
        "* Каждая строка имеет формат class x_center y_center width height.\n",
        "* Координаты нормализованы по относительно размера изображения\n",
        "* Индексация классов начинается с нуля\n",
        "\n",
        "Структура каталогов набора данных формата YOLOv5\n",
        "```\n",
        "base_dir\n",
        "├── images           # изображения\n",
        "│   ├── test\n",
        "│   ├── train\n",
        "│   └── validation\n",
        "└── labels           # аннотации\n",
        "    ├── test\n",
        "    ├── train\n",
        "    └── validation\n",
        "```    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Подготовка к преобразованию данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def extract_info_from_xml(xml_file):\n",
        "    \n",
        "    '''\n",
        "        Извлекает описание объектов из формата XML и преобразует данные в словарь\n",
        "    '''\n",
        "    root = ET.parse(xml_file).getroot()\n",
        "    \n",
        "    # инициализация словаря\n",
        "    info_dict = {}\n",
        "    info_dict['bboxes'] = []\n",
        "\n",
        "    # парсинг XML\n",
        "    for elem in root:\n",
        "        # получение имени файла\n",
        "        if elem.tag == \"filename\":\n",
        "            info_dict['filename'] = elem.text\n",
        "            \n",
        "        # получение размера файла\n",
        "        elif elem.tag == \"size\":\n",
        "            image_size = [-1,-1,-1]\n",
        "            for subelem in elem:\n",
        "                if subelem.tag == \"width\":\n",
        "                    image_size[0] = int(subelem.text)\n",
        "                if subelem.tag == \"height\":\n",
        "                    image_size[1] = int(subelem.text)\n",
        "                if subelem.tag == \"depth\":\n",
        "                    image_size[2] = int(subelem.text)\n",
        "            \n",
        "            info_dict['image_size'] = tuple(image_size)\n",
        "        \n",
        "        # получение описания рамок\n",
        "        elif elem.tag == \"object\":\n",
        "            bbox = {}\n",
        "            for subelem in elem:\n",
        "                if subelem.tag == \"name\":\n",
        "                    bbox[\"class\"] = subelem.text\n",
        "                    \n",
        "                elif subelem.tag == \"bndbox\":\n",
        "                    for subsubelem in subelem:\n",
        "                        bbox[subsubelem.tag] = int(float(subsubelem.text))            \n",
        "            info_dict['bboxes'].append(bbox)\n",
        "    \n",
        "    return info_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bboxes': [{'class': 'person',\n",
              "   'xmax': 264,\n",
              "   'xmin': 71,\n",
              "   'ymax': 302,\n",
              "   'ymin': 8}],\n",
              " 'filename': '2011_003300.jpg',\n",
              " 'image_size': (500, 375, 3)}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extract_info_from_xml(\"data/VOCdevkit/VOC2012/Annotations/2011_003300.xml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tvmonitor': 0,\n",
              " 'aeroplane': 1,\n",
              " 'bicycle': 2,\n",
              " 'car': 3,\n",
              " 'bottle': 4,\n",
              " 'horse': 5,\n",
              " 'boat': 6,\n",
              " 'motorbike': 7,\n",
              " 'pottedplant': 8,\n",
              " 'bus': 9,\n",
              " 'sheep': 10,\n",
              " 'cat': 11,\n",
              " 'person': 12,\n",
              " 'sofa': 13,\n",
              " 'cow': 14,\n",
              " 'bird': 15,\n",
              " 'chair': 16,\n",
              " 'train': 17,\n",
              " 'diningtable': 18,\n",
              " 'dog': 19}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# получение словаря объектов для отображения имени на идентификатор\n",
        "annotations_dir = 'data/VOCdevkit/VOC2012/Annotations'\n",
        "images_dir = 'data/VOCdevkit/VOC2012/JPEGImages'\n",
        "a = [os.path.join(annotations_dir, x) for x in os.listdir(annotations_dir) if x[-3:] == \"xml\"]\n",
        "a = [extract_info_from_xml(x) for x in a] \n",
        "a = [x[\"bboxes\"] for x in  a]\n",
        "a = [[z[\"class\"] for z in x] for x in a]\n",
        "a = set(sum(a, []))\n",
        "a.sort()\n",
        "print(a)\n",
        "class_name_to_id_mapping = {x: i for (i, x) in enumerate(a)}\n",
        "\n",
        "class_name_to_id_mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_to_yolov5(info_dict):\n",
        "    '''\n",
        "        Преобразование словаря с описанием в формат yolo и запись на диск\n",
        "    '''\n",
        "    print_buffer = []\n",
        "    \n",
        "    # For each bounding box\n",
        "    for b in info_dict[\"bboxes\"]:\n",
        "        try:\n",
        "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
        "        except KeyError:\n",
        "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
        "        \n",
        "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
        "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
        "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
        "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
        "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
        "        \n",
        "        # Normalise the co-ordinates by the dimensions of the image\n",
        "        image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
        "        b_center_x /= image_w \n",
        "        b_center_y /= image_h \n",
        "        b_width    /= image_w \n",
        "        b_height   /= image_h \n",
        "        \n",
        "        #Write the bbox details to the file \n",
        "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
        "        \n",
        "    # Name of the file which we have to save \n",
        "    save_file_name = os.path.join(annotations_dir, info_dict[\"filename\"].replace(\"jpg\", \"txt\"))\n",
        "    \n",
        "    # Save the annotation to disk\n",
        "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17125/17125 [00:18<00:00, 902.43it/s] \n"
          ]
        }
      ],
      "source": [
        "# Получение описаний\n",
        "annotations = [os.path.join(annotations_dir, x) for x in os.listdir(annotations_dir) if x[-3:] == \"xml\"]\n",
        "annotations.sort()\n",
        "\n",
        "# Конвертация\n",
        "for ann in tqdm(annotations):\n",
        "    info_dict = extract_info_from_xml(ann)\n",
        "    convert_to_yolov5(info_dict)\n",
        "annotations = [os.path.join(annotations_dir, x) for x in os.listdir(annotations_dir) if x[-3:] == \"txt\"]\n",
        "# annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Тестирование аннотаций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/VOCdevkit/VOC2012/Annotations\\2010_006174.txt\n",
            "[[12.0, 0.466, 0.686, 0.128, 0.399], [12.0, 0.979, 0.614, 0.042, 0.291]]\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-956ea301fc47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Получим имя файла изображеня\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Annotations\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"JPEGImages\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# Развернем словарь\n",
        "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
        "\n",
        "def plot_bounding_box(image, annotation_list):\n",
        "    '''\n",
        "    Отрисовка изображения и рамок\n",
        "    '''\n",
        "    annotations = np.array(annotation_list)\n",
        "    w, h = image.size\n",
        "    \n",
        "    plotted_image = ImageDraw.Draw(image)\n",
        "\n",
        "    transformed_annotations = np.copy(annotations)\n",
        "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
        "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
        "    \n",
        "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
        "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
        "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
        "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
        "    \n",
        "    for ann in transformed_annotations:\n",
        "        obj_cls, x0, y0, x1, y1 = ann\n",
        "        plotted_image.rectangle(((x0,y0), (x1,y1)), width=2)\n",
        "        \n",
        "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))].upper())\n",
        "    \n",
        "    plt.figure(figsize=(1, 1))\n",
        "    plt.imshow(np.array(image), aspect=1)\n",
        "    plt.show()\n",
        "\n",
        "# Получим случайное описание\n",
        "annotation_file = random.choice(annotations)\n",
        "print(annotation_file)\n",
        "with open(annotation_file, \"r\") as file:\n",
        "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
        "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
        "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
        "print(annotation_list)\n",
        "# Получим имя файла изображеня \n",
        "image_file = annotation_file.replace(\"Annotations\", \"JPEGImages\").replace(\"txt\", \"jpg\")\n",
        "assert os.path.exists(image_file)\n",
        "\n",
        "image = Image.open(image_file)\n",
        "\n",
        "plot_bounding_box(image, annotation_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Разбиение набора данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read images and annotations\n",
        "images_dir = 'data/VOCdevkit/VOC2012/JPEGImages'\n",
        "\n",
        "images = [os.path.join(images_dir, x) for x in os.listdir(images_dir)]\n",
        "annotations = [os.path.join(annotations_dir, x) for x in os.listdir(annotations_dir) if x[-3:] == \"txt\"]\n",
        "\n",
        "images.sort()\n",
        "annotations.sort()\n",
        "\n",
        "# Split the dataset into train-valid-test splits \n",
        "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
        "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "�������� ��� 䠩� data\\VOCdevkit\\VOC2012\\JPEGImages\\train 㦥 �������.\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\\VOCdevkit\\VOC2012\\JPEGImages\\train \n",
        "!mkdir data\\VOCdevkit\\VOC2012\\JPEGImages\\val \n",
        "!mkdir data\\VOCdevkit\\VOC2012\\JPEGImages\\test \n",
        "!mkdir data\\VOCdevkit\\VOC2012\\Annotations\\train \n",
        "!mkdir data\\VOCdevkit\\VOC2012\\Annotations\\val \n",
        "!mkdir data\\VOCdevkit\\VOC2012\\Annotations\\test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Utility function to move images \n",
        "def move_files_to_folder(list_of_files, destination_folder):\n",
        "    for f in list_of_files:\n",
        "        try:\n",
        "            shutil.move(f, destination_folder)\n",
        "        except:\n",
        "            print(f)\n",
        "            assert False\n",
        "\n",
        "# Move the splits into their folders\n",
        "move_files_to_folder(train_images, 'data\\VOCdevkit\\VOC2012\\JPEGImages/train')\n",
        "move_files_to_folder(val_images, 'data\\VOCdevkit\\VOC2012\\JPEGImages/val/')\n",
        "move_files_to_folder(test_images, 'data\\VOCdevkit\\VOC2012\\JPEGImages/test/')\n",
        "move_files_to_folder(train_annotations, 'data\\VOCdevkit\\VOC2012\\Annotations/train/')\n",
        "move_files_to_folder(val_annotations, 'data\\VOCdevkit\\VOC2012\\Annotations/val/')\n",
        "move_files_to_folder(test_annotations, 'data\\VOCdevkit\\VOC2012\\Annotations/test/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active code page: 65001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the file specified.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "homework_01_YOLO.ipynb\n",
            "README.md\n",
            "yolov5\n",
            "data\n",
            "homework_01_YOLO.ipynb\n",
            "README.md\n",
            "yolov5\n"
          ]
        }
      ],
      "source": [
        "!chcp 65001\n",
        "# mv annotations labels\n",
        "!rename annotations labels\n",
        "!cd yolov5\n",
        "!dir /B\n",
        "!cd yolov5\n",
        "!dir /B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Файл конфигурации данных\n",
        "Создадим файл `voc_data.yaml`\n",
        "\n",
        "```\n",
        "# путь к данным\n",
        "train: ./data/VOCdevkit/VOC2021/images/train/ \n",
        "val:  ./data/VOCdevkit/VOC2021/images/val/\n",
        "test: ./data/VOCdevkit/VOC2021/images/test/\n",
        "\n",
        "# число классов\n",
        "nc: 20\n",
        "\n",
        "# имена классов\n",
        "names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
        "        'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Конфигурационный файл гиперпараметров\n",
        "Будем использовать `./yolov5/data/hips/hyp.VOC.yaml`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Обучение\n",
        "`python train.py --batch 128 --weights yolov5m6.pt --data VOC.yaml --epochs 50 --img 512 --hyp hyp.scratch-med.yaml --evolve`\n",
        "C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\python.exe  train.py --batch 128 --weights data/models/yolov5m6.pt --data ../voc_data.yaml --epochs 50 --img 512 --hyp data/hyps/hyp.VOC.yaml --workers=8 --name=my_yolo --evolve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (offline), for updates see https://github.com/ultralytics/yolov5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/data/models/yolov5m6.pt, cfg=, data=voc_data.yaml, hyp=yolov5/data/hyps/hyp.VOC.yaml, epochs=50, batch_size=128, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=300, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=my_yolo, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLOv5  v6.1-191-gd29df68 Python-3.7.9 torch-1.11.0+cpu CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00334, lrf=0.15135, momentum=0.74832, weight_decay=0.00025, warmup_epochs=3.3835, warmup_momentum=0.59462, warmup_bias_lr=0.18657, box=0.02, cls=0.21638, cls_pw=0.5, obj=0.51728, obj_pw=0.67198, iou_t=0.2, anchor_t=3.3744, fl_gamma=0.0, hsv_h=0.01041, hsv_s=0.54703, hsv_v=0.27739, degrees=0.0, translate=0.04591, scale=0.75544, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.85834, mixup=0.04266, copy_paste=0.0, anchors=3.412\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5  runs (RECOMMENDED)\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to C:\\Users\\brovkin_vn\\AppData\\Roaming\\Ultralytics\\Arial.ttf...\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1277, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1323, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1272, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1032, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 972, in send\n",
            "    self.connect()\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1439, in connect\n",
            "    super().connect()\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 944, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\socket.py\", line 728, in create_connection\n",
            "    raise err\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "TimeoutError: [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"yolov5/train.py\", line 670, in <module>\n",
            "    main(opt)\n",
            "  File \"yolov5/train.py\", line 647, in main\n",
            "    results = train(hyp.copy(), opt, device, callbacks)\n",
            "  File \"yolov5/train.py\", line 107, in train\n",
            "    data_dict = data_dict or check_dataset(data)  # check if None\n",
            "  File \"d:\\aaa\\Projects\\0058_DS\\hw-01\\yolov5\\utils\\general.py\", line 504, in check_dataset\n",
            "    check_font('Arial.ttf' if is_ascii(data['names']) else 'Arial.Unicode.ttf', progress=True)  # download fonts\n",
            "  File \"d:\\aaa\\Projects\\0058_DS\\hw-01\\yolov5\\utils\\general.py\", line 446, in check_font\n",
            "    torch.hub.download_url_to_file(url, str(file), progress=progress)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\hub.py\", line 457, in download_url_to_file\n",
            "    u = urlopen(req)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"C:\\Users\\brovkin_vn\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\", line 1352, in do_open\n",
            "    raise URLError(err)\n",
            "urllib.error.URLError: <urlopen error [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера>\n"
          ]
        }
      ],
      "source": [
        "!python yolov5/train.py --batch 128 --weights yolov5/data/models/yolov5m6.pt --data voc_data.yaml --epochs 50 --img 512 --hyp yolov5/data/hyps/hyp.VOC.yaml --workers=8 --name=my_yolo --evolve"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Модуль_12_YOLO_дз.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03bed50e8e424125a1a94bfb29e95d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27882cde128d4e92b8621c474a592fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ca7602a5fd42c3b261de21d8c6aa17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536fae0cc9044c2daa224dfeb367d461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a49489725b6434889e60368e2380635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd12dc276d784fd882f6c5a88be1bf5b",
              "IPY_MODEL_c6bf9daa3b40463e82d88d5f3fa7024c",
              "IPY_MODEL_d79cd9fa921847b58b42a147aa808523"
            ],
            "layout": "IPY_MODEL_27882cde128d4e92b8621c474a592fbf"
          }
        },
        "ad9993e2585d413aa165112fc357e741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70e1703b7a24fdf8b53f7c4f972df12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6bf9daa3b40463e82d88d5f3fa7024c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ca7602a5fd42c3b261de21d8c6aa17",
            "max": 14795158,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_536fae0cc9044c2daa224dfeb367d461",
            "value": 14795158
          }
        },
        "d79cd9fa921847b58b42a147aa808523": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad9993e2585d413aa165112fc357e741",
            "placeholder": "​",
            "style": "IPY_MODEL_daece13ba3d0434190868b1e601983ea",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 81.3MB/s]"
          }
        },
        "daece13ba3d0434190868b1e601983ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd12dc276d784fd882f6c5a88be1bf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03bed50e8e424125a1a94bfb29e95d9e",
            "placeholder": "​",
            "style": "IPY_MODEL_b70e1703b7a24fdf8b53f7c4f972df12",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
